<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>

<property>
  <name>dfs.datanode.balance.bandwidthPerSec</name>
  <value>1m</value>
  <description>
        Specifies the maximum amount of bandwidth that each datanode
        can utilize for the balancing purpose in term of
        the number of bytes per second. You can use the following
        suffix (case insensitive):
        k(kilo), m(mega), g(giga), t(tera), p(peta), e(exa)to specify the size
        (such as 128k, 512m, 1g, etc.).
        Or provide complete size in bytes (such as 134217728 for 128 MB).
  </description>
</property>

<property>
  <name>dfs.image.parallel.load</name>
  <value>true</value>
  <description>
        If true, write sub-section entries to the fsimage index so it can
        be loaded in parallel. Also controls whether parallel loading
        will be used for an image previously created with sub-sections.
        If the image contains sub-sections and this is set to false,
        parallel loading will not be used.
        Parallel loading is not compatible with image compression,
        so if dfs.image.compress is set to true this setting will be
        ignored and no parallel loading will occur.
        Enabling this feature may impact rolling upgrades and downgrades if
        the previous version does not support this feature. If the feature was
        enabled and a downgrade is required, first set this parameter to
        false and then save the namespace to create a fsimage with no
        sub-sections and then perform the downgrade.
  </description>
</property>

<property>
  <name>dfs.datanode.sync.behind.writes</name>
  <value>false</value>
  <description>
        If this configuration is enabled, the datanode will instruct the
        operating system to enqueue all written data to the disk immediately
        after it is written. This differs from the usual OS policy which
        may wait for up to 30 seconds before triggering writeback.

        This may improve performance for some workloads by smoothing the
        IO profile for data written to disk.

        If the Hadoop native libraries are not available, this configuration
        has no effect.
  </description>
</property>

<property>
  <name>dfs.client.read.shortcircuit.skip.checksum</name>
  <value>true</value>
  <description>
    If this configuration parameter is set,
    short-circuit local reads will skip checksums.
    This is normally not recommended,
    but it may be useful for special setups.
    You might consider using this
    if you are doing your own checksumming outside of HDFS.
  </description>
</property>

<property>
  <name>dfs.content-summary.limit</name>
  <value>5000</value>
  <description>
    The maximum content summary counts allowed in one locking period. 0 or a negative number
    means no limit (i.e. no yielding).
  </description>
</property>

<property>
  <name>dfs.qjournal.start-segment.timeout.ms</name>
  <value>40000</value>
  <description>
    Quorum timeout in milliseconds for starting a log segment.
  </description>
</property>

<property>
  <name>dfs.namenode.gc.time.monitor.enable</name>
  <value>false</value>
    <description>
      Enable the GcTimePercentage metrics in NameNode's JvmMetrics. It will
      start a thread(GcTimeMonitor) computing the metric.
    </description>
</property>

<property>
  <name>dfs.permissions.allow.owner.set.quota</name>
  <value>false</value>
    <description>
      Whether the owner(not superuser) of a directory can set quota of his sub
      directories when permissions is enabled. Default value is false;
    </description>
</property>

</configuration>
