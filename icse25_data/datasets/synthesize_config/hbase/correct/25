<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>

<property>
  <name>zookeeper.recovery.retry.maxsleeptime</name>
  <value>30000</value>
    <description>Max sleep time before retry zookeeper operations in milliseconds,
    a max time is needed here so that sleep time won't grow unboundedly
    </description>
</property>

<property>
  <name>hbase.zookeeper.property.syncLimit</name>
  <value>10</value>
    <description>Property from ZooKeeper's config zoo.cfg.
    The number of ticks that can pass between sending a request and getting an
    acknowledgment.</description>
</property>

<property>
  <name>hbase.zookeeper.property.clientPort</name>
  <value>1090</value>
    <description>Property from ZooKeeper's config zoo.cfg.
    The port at which the clients will connect.</description>
</property>

<property>
  <name>hbase.client.max.total.tasks</name>
  <value>200</value>
    <description>The maximum number of concurrent mutation tasks a single HTable instance will
    send to the cluster.</description>
</property>

<property>
  <name>hbase.client.keyvalue.maxsize</name>
  <value>20971520</value>
    <description>Specifies the combined maximum allowed size of a KeyValue
    instance. This is to set an upper boundary for a single entry saved in a
    storage file. Since they cannot be split it helps avoiding that a region
    cannot be split any further because the data is too large. It seems wise
    to set this to a fraction of the maximum region size. Setting it to zero
    or less disables the check.</description>
</property>

<property>
  <name>hbase.regionserver.thread.compaction.throttle</name>
  <value>1342177280</value>
    <description>There are two different thread pools for compactions, one for large compactions and
      the other for small compactions. This helps to keep compaction of lean tables (such as
      hbase:meta) fast. If a compaction is larger than this threshold, it
      goes into the large compaction pool. In most cases, the default value is appropriate. Default:
      2 x hbase.hstore.compaction.max x hbase.hregion.memstore.flush.size (which defaults to 128MB).
      The value field assumes that the value of hbase.hregion.memstore.flush.size is unchanged from
      the default.</description>
</property>

<property>
  <name>hbase.dfs.client.read.shortcircuit.buffer.size</name>
  <value>131072</value>
    <description>If the DFSClient configuration
    dfs.client.read.shortcircuit.buffer.size is unset, we will
    use what is configured here as the short circuit read default
    direct byte buffer size. DFSClient native default is 1MB; HBase
    keeps its HDFS files open so number of file blocks * 1MB soon
    starts to add up and threaten OOME because of a shortage of
    direct memory.  So, we set it down from the default.  Make
    it > the default hbase block size set in the HColumnDescriptor
    which is usually 64k.
    </description>
</property>

<property>
  <name>hbase.hstore.checksum.algorithm</name>
  <value>CRC32C</value>
    <description>
      Name of an algorithm that is used to compute checksums. Possible values
      are NULL, CRC32, CRC32C.
    </description>
</property>

</configuration>
