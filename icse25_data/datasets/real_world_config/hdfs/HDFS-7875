<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>

<property>
  <name>dfs.namenode.name.dir</name>
  <value>/valid/dir2</value>
  <description>Determines where on the local filesystem the DFS name node
      should store the name table(fsimage).  If this is a comma-delimited list
      of directories then the name table is replicated in all of the
      directories, for redundancy. </description>
</property>

<property>
  <name>dfs.replication.max</name>
  <value>1024</value>
  <description>Maximal block replication.
  </description>
</property>

<property>
  <name>dfs.datanode.directoryscan.interval</name>
  <value>21600s</value>
  <description>Interval in seconds for Datanode to scan data directories and
  reconcile the difference between blocks in memory and on the disk.
  Support multiple time unit suffix(case insensitive), as described
  in dfs.heartbeat.interval.If no time unit is specified then seconds
  is assumed.
  </description>
</property>

<property>
  <name>dfs.datanode.failed.volumes.tolerated</name>
  <value>10</value>
  <description>The number of volumes that are allowed to
  fail before a datanode stops offering service. By default
  any volume failure will cause a datanode to shutdown.
  The value should be greater than or equal to -1 , -1 represents minimum
  1 valid volume.
  </description>
</property>

<property>
  <name>dfs.datanode.data.dir</name>
  <value>file://${hadoop.tmp.dir}/dfs/data</value>
  <description>Determines where on the local filesystem an DFS data node
  should store its blocks.  If this is a comma-delimited
  list of directories, then data will be stored in all named
  directories, typically on different devices. The directories should be tagged
  with corresponding storage types ([SSD]/[DISK]/[ARCHIVE]/[RAM_DISK]) for HDFS
  storage policies. The default storage type will be DISK if the directory does
  not have a storage type tagged explicitly. Directories that do not exist will
  be created if local filesystem permission allows.
  </description>
</property>

<property>
  <name>dfs.datanode.socket.reuse.keepalive</name>
  <value>2000</value>
  <description>
    The window of time in ms before the DataXceiver closes a socket for a
    single request.  If a second request occurs within that window, the
    socket can be reused.
  </description>
</property>

<property>
  <name>dfs.journalnode.edit-cache-size.bytes</name>
  <value>2097152</value>
  <description>
    The size, in bytes, of the in-memory cache of edits to keep on the
    JournalNode. This cache is used to serve edits for tailing via the RPC-based
    mechanism, and is only enabled when dfs.ha.tail-edits.in-progress is true.
    Transactions range in size but are around 200 bytes on average, so the
    default of 1MB can store around 5000 transactions.
  </description>
</property>

<property>
  <name>dfs.namenode.snapshotdiff.listing.limit</name>
  <value>1000</value>
  <description>
    Limit the number of entries generated by getSnapshotDiffReportListing within
    one rpc call to the namenode.If less or equal to zero, at most
    DFS_NAMENODE_SNAPSHOT_DIFF_LISTING_LIMIT_DEFAULT (= 1000) will be sent
    across to the client within one rpc call.
  </description>
</property>

</configuration>
