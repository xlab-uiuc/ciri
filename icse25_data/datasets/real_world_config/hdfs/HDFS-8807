<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>

<property>
  <name>dfs.namenode.edits.dir</name>
  <value>/valid/dir2</value>
  <description>Determines where on the local filesystem the DFS name node
      should store the transaction (edits) file. If this is a comma-delimited list
      of directories then the transaction file is replicated in all of the
      directories, for redundancy. Default value is same as dfs.namenode.name.dir
  </description>
</property>

<property>
  <name>dfs.namenode.edits.journal-plugin.qjournal</name>
  <value>org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager</value>
</property>

<property>
  <name>dfs.namenode.service.handler.count</name>
  <value>10</value>
  <description>The number of Namenode RPC server threads that listen to
  requests from DataNodes and from all other non-client nodes.
  dfs.namenode.service.handler.count will be valid only if
  dfs.namenode.servicerpc-address is configured.
  </description>
</property>

<property>
  <name>dfs.bytes-per-checksum</name>
  <value>1024</value>
  <description>The number of bytes per checksum.  Must not be larger than
  dfs.stream-buffer-size</description>
</property>

<property>
  <name>dfs.namenode.checkpoint.dir</name>
  <value>/valid/dir1</value>
  <description>Determines where on the local filesystem the DFS secondary
      name node should store the temporary images to merge.
      If this is a comma-delimited list of directories then the image is
      replicated in all of the directories for redundancy.
  </description>
</property>

<property>
  <name>dfs.namenode.num.checkpoints.retained</name>
  <value>4</value>
  <description>The number of image checkpoint files (fsimage_*) that will be retained by
  the NameNode and Secondary NameNode in their storage directories. All edit
  logs (stored on edits_* files) necessary to recover an up-to-date namespace from the oldest retained
  checkpoint will also be retained.
  </description>
</property>

<property>
  <name>dfs.journalnode.https-address</name>
  <value>0.0.0.0:8481</value>
  <description>
    The address and port the JournalNode HTTPS server listens on.
    If the port is 0 then the server will start on a free port.
  </description>
</property>

<property>
  <name>dfs.datanode.data.dir</name>
  <value>   file://${hadoop.tmp.dir}/dfs/data</value>
  <description>Determines where on the local filesystem an DFS data node
  should store its blocks.  If this is a comma-delimited
  list of directories, then data will be stored in all named
  directories, typically on different devices. The directories should be tagged
  with corresponding storage types ([SSD]/[DISK]/[ARCHIVE]/[RAM_DISK]) for HDFS
  storage policies. The default storage type will be DISK if the directory does
  not have a storage type tagged explicitly. Directories that do not exist will
  be created if local filesystem permission allows.
  </description>
</property>

</configuration>
